## 进程和线程

### 进程和线程有什么区别？

1. 进程是对运行时程序的封装，是系统进行**资源分配和调度**的基本单元，而线程是进程的子任务，是**CPU分配和调度**的基本单元。
2. 一个进程可以有多个线程，但是一个线程只能属于一个进程。
3. 进程的创建需要系统分配内存和CPU，文件句柄等资源，销毁时也要进行相应的回收，所以进程的管理开销很大；但是线程的管理开销则很小。
4. 进程之间不会相互影响；而一个线程崩溃会导致进程崩溃，从而影响同个进程里面的其他线程。

- 进程有自己的独立地址空间，线程共享所属进程的地址空间；
- 进程是拥有系统资源的一个独立单位，而线程自己基本上不拥有系统资源，只拥有一点在运行中必不可少的资源(如程序计数器,一组寄存器和栈)，和其他线程共享本进程的相关资源如内存、I/O、cpu等；
- 在进程切换时，涉及到整个当前进程CPU环境的保存环境的设置以及新被调度运行的CPU环境的设置，而线程切换只需保存和设置少量的寄存器的内容，并不涉及存储器管理方面的操作，可见，进程切换的开销远大于线程切换的开销；
- 线程之间的通信更方便，同一进程下的线程共享全局变量等数据，而进程之间的通信需要以进程间通信(IPC)的方式进行；
- 多线程程序只要有一个线程崩溃，整个程序就崩溃了，但多进程程序中一个进程崩溃并不会对其它进程造成影响，因为进程有自己的独立地址空间，因此多进程更加健壮

#### 什么时候多进程，什么时候多线程

https://blog.csdn.net/yu876876/article/details/82810178

* 频繁修改：需要频繁创建和销毁的优先使用**多线程**
* 计算量：需要大量计算的优先使用**多线程**  因为需要消耗大量CPU资源且切换频繁，所以多线程好一点
* 相关性：任务间相关性比较强的用**多线程**，相关性比较弱的用多进程。因为线程之间的数据共享和同步比较简单。
* 多分布：可能要扩展到多机分布的用**多进程**，多核分布的用**多线程**。

但是实际中更常见的是进程加线程的结合方式，并不是非此即彼的。

#### 同一进程中的线程可以共享哪些数据？

* 该进程的地址空间
* 全局变量
* 堆空间

线程的栈空间是自己独有的

<details open="">
<summary>展开</summary>
<ul>
<li>进程代码段</li>
<li>进程的公有数据（全局变量、静态变量...）</li>
<li>进程打开的文件描述符</li>
<li>进程的当前目录</li>
<li>信号处理器/信号处理函数：对收到的信号的处理方式</li>
<li>进程ID与进程组ID</li>
</ul>
</details>

#### 线程独占哪些资源？

<details open="">
<summary>展开</summary>
<ul>
<li>线程ID</li>
<li>一组寄存器的值</li>
<li>线程自身的栈（堆是共享的）</li>
<li>错误返回码：线程可能会产生不同的错误返回码，一个线程的错误返回码不应该被其它线程修改；</li>
<li>信号掩码/信号屏蔽字(Signal mask)：表示是否屏蔽/阻塞相应的信号（SIGKILL,SIGSTOP除外）</li>
</ul>
</details>

### 进程间通信有哪些方式？

进程之间的通信方式主要有六种，包括**管道，信号量，消息队列，信号，共享内存，套接字**。

* **管道**：

  - 管道是半双工的，数据只能向一个方向流动；需要双方通信时，需要建立起两个管道；
  - 一个进程向管道中写的内容被管道另一端的进程读出。写入的内容每次都添加在管道缓冲区的末尾，并且每次都是从缓冲区的头部读出数据；
  - 匿名管道pipe和命名管道除了建立，打开，删除的方式不同外，其余都是一样的。匿名管道只允许有亲缘关系的进程之间通信，也就是父子进程之间的通信，命名管道允许具有非亲缘关系的进程间通信。

  管道的底层实现 https://segmentfault.com/a/1190000009528245

* **信号量**：信号量是一个计数器，可以用来控制多个进程对共享资源的访问。信号量只有等待和发送两种操作。等待(P(sv))就是将其值减一或者挂起进程，发送(V(sv))就是将其值加一或者将进程恢复运行。

* **信号**：信号是Linux系统中用于进程之间通信或操作的一种机制，信号可以在任何时候发送给某一进程，而无须知道该进程的状态。如果该进程并未处于执行状态，则该信号就由内核保存起来，知道该进程恢复执行并传递给他为止。如果一个信号被进程设置为阻塞，则该信号的传递被延迟，直到其阻塞被取消时才被传递给进程。 信号是开销最小的

* **共享内存**：共享内存允许两个或多个进程共享一个给定的存储区，这一段存储区可以被两个或两个以上的进程映射至自身的地址空间中，就像由malloc()分配的内存一样使用。一个进程写入共享内存的信息，可以被其他使用这个共享内存的进程，通过一个简单的内存读取读出，从而实现了进程间的通信。共享内存的效率最高，缺点是没有提供同步机制，需要使用锁等其他机制进行同步。

* **消息队列**：消息队列就是一个消息的链表，是一系列保存在内核中消息的列表。用户进程可以向消息队列添加消息，也可以向消息队列读取消息。
  消息队列与管道通信相比，其优势是对每个消息指定特定的消息类型，接收的时候不需要按照队列次序，而是可以根据自定义条件接收特定类型的消息。
  可以把消息看做一个记录，具有特定的格式以及特定的优先级。对消息队列有写权限的进程可以向消息队列中按照一定的规则添加新消息，对消息队列有读权限的进程可以从消息队列中读取消息。

* **套接字**：套接口也是一种进程间通信机制，与其他通信机制不同的是，<u>它可用于不同设备及其间的进程通信</u>。

### 进程同步问题

>  进程的同步是目的，而进程间通信是实现进程同步的手段

<details open="">
<summary>管程 Monitor</summary>
<p>管程将共享变量以及对这些共享变量的操作封装起来，形成一个具有一定接口的功能模块，这样只能通过管程提供的某个过程才能访问管程中的资源。进程只能互斥地使用管程，使用完之后必须释放管程并唤醒入口等待队列中的进程。</p>
<p>当一个进程试图进入管程时，在<strong>入口等待队列</strong>等待。若P进程唤醒了Q进程，则Q进程先执行，P在<strong>紧急等待队列</strong>中等待。（<strong>HOARE管程</strong>）</p>
<p>wait操作：执行wait操作的进程进入条件变量链末尾，唤醒紧急等待队列或者入口队列中的进程；signal操作：唤醒条件变量链中的进程，自己进入紧急等待队列，若条件变量链为空，则继续执行。（<strong>HOARE管程</strong>）</p>
<p><strong>MESA管程</strong>：将HOARE中的signal换成了notify（或者broadcast通知所有满足条件的），进行通知而不是立马交换管程的使用权，在合适的时候，条件队列首位的进程可以进入，进入之前必须用while检查条件是否合适。优点：没有额外的进程切换</p>
</details>

<details open="">
<summary>生产者-消费者问题</summary>
<blockquote>
<p>问题描述：使用一个缓冲区来存放数据，只有缓冲区没有满，生产者才可以写入数据；只有缓冲区不为空，消费者才可以读出数据</p>
</blockquote>
<p>代码实现：</p>
<div class="highlight highlight-source-c position-relative"><pre><span class="pl-c"><span class="pl-c">//</span> 伪代码描述 </span>
<span class="pl-c"><span class="pl-c">//</span> 定义信号量 full记录缓冲区物品数量 empty代表缓冲区空位数量 mutex为互斥量</span>
semaphore full = <span class="pl-c1">0</span>, empty = n, mutex = <span class="pl-c1">1</span>;

<span class="pl-c"><span class="pl-c">//</span> 生产者进程</span>
<span class="pl-k">void</span> <span class="pl-en">producer</span>(){
	<span class="pl-k">do</span>{
   	  <span class="pl-c1">P</span>(empty);
	  <span class="pl-c1">P</span>(mutex);

     <span class="pl-c"><span class="pl-c">//</span> 生产者进行生产</span>
   	
   	  <span class="pl-c1">V</span>(mutex);
   	  <span class="pl-c1">V</span>(full);
 	} <span class="pl-k">while</span>(<span class="pl-c1">1</span>);
}

<span class="pl-k">void</span> <span class="pl-en">consumer</span>(){
	<span class="pl-k">do</span>{
	  <span class="pl-c1">P</span>(full);
	  <span class="pl-c1">P</span>(mutex);

    	<span class="pl-c"><span class="pl-c">//</span> 消费者进行消费</span>

	  <span class="pl-c1">V</span>(mutex);
	  <span class="pl-c1">V</span>(empty);
 	} <span class="pl-k">while</span>(<span class="pl-c1">1</span>);
}
</pre></div>
</details>

<details open="">
<summary>哲学家就餐问题</summary>
<blockquote>
<p>问题描述：有五位哲学家围绕着餐桌坐，每一位哲学家要么思考，要么吃饭。为了吃饭，哲学家必须拿起两双筷子（分别放于左右两端）不幸的是，筷子的数量和哲学家相等，所以每只筷子必须由两位哲学家共享。</p>
</blockquote>
<p>代码实现：</p>
<div class="highlight highlight-source-c position-relative"><pre>#<span class="pl-k">define</span> <span class="pl-en">N</span> <span class="pl-c1">5</span>  <span class="pl-c"><span class="pl-c">//</span> number of philosopher</span>
#<span class="pl-k">define</span> <span class="pl-en">LEFT</span> (i + N - <span class="pl-c1">1</span>)%N <span class="pl-c"><span class="pl-c">//</span> number of i's left neighbors</span>
#<span class="pl-k">define</span> <span class="pl-en">RIGHT</span> (i + <span class="pl-c1">1</span>)%N <span class="pl-c"><span class="pl-c">//</span> number of i's right neighbors</span>
#<span class="pl-k">define</span> <span class="pl-en">THINKING</span> <span class="pl-c1">0</span>
#<span class="pl-k">define</span> <span class="pl-en">HUNGRY</span> <span class="pl-c1">1</span>
#<span class="pl-k">define</span> <span class="pl-en">EATING</span> <span class="pl-c1">2</span>
<span class="pl-k">typedef</span> <span class="pl-k">int</span> semaphore;
<span class="pl-k">int</span> state[N]; <span class="pl-c"><span class="pl-c">//</span> array to keep track of everyone's state</span>
semaphore mutex = <span class="pl-c1">1</span>; <span class="pl-c"><span class="pl-c">//</span> mutual exclusion of critical region</span>
semaphore s[N]; 

<span class="pl-k">void</span> <span class="pl-en">philosopher</span>(<span class="pl-k">int</span> i) {
	<span class="pl-k">while</span> (<span class="pl-c1">TRUE</span>) {
		<span class="pl-c1">think</span>();
		<span class="pl-c1">take_forks</span>(i);
		<span class="pl-c1">eat</span>();
		<span class="pl-c1">put_forks</span>(i);
	}
}

<span class="pl-k">void</span> <span class="pl-en">take_forks</span>(<span class="pl-k">int</span> i) {
	<span class="pl-c1">down</span>(&amp;mutex); <span class="pl-c"><span class="pl-c">//</span> enter critical region</span>
	state[i] = HUNGRY; <span class="pl-c"><span class="pl-c">//</span> record that i is hungry</span>
	<span class="pl-c1">test_forks</span>(i); <span class="pl-c"><span class="pl-c">//</span> try to acquire two forks</span>
	<span class="pl-c1">up</span>(&amp;mutex); <span class="pl-c"><span class="pl-c">//</span> exit critical region</span>
	<span class="pl-c1">down</span>(&amp;s[i]); <span class="pl-c"><span class="pl-c">//</span> block if forks are not acquired</span>
}

<span class="pl-k">void</span> <span class="pl-en">put_forks</span>(<span class="pl-k">int</span> i) {
	<span class="pl-c1">down</span>(&amp;mutex); <span class="pl-c"><span class="pl-c">//</span> enter critical region</span>
	state[i] = THINKING; <span class="pl-c"><span class="pl-c">//</span> record that has finished eating</span>
	<span class="pl-c1">test_forks</span>(LEFT); <span class="pl-c"><span class="pl-c">//</span> see if left neighbor can now eat</span>
	<span class="pl-c1">test_forks</span>(RIGHT); <span class="pl-c"><span class="pl-c">//</span> see if right neighbor can now eat</span>
	<span class="pl-c1">up</span>(&amp;mutex); <span class="pl-c"><span class="pl-c">//</span> exit critical region</span>
}

<span class="pl-k">void</span> <span class="pl-en">test_forks</span>(<span class="pl-k">int</span> i) {
	<span class="pl-k">if</span> (state[i] == HUNGRY &amp;&amp; state[LEFT] != EATING &amp;&amp; state[RIGHT] != EATING) {
		state[i] = EATING;
		<span class="pl-c1">up</span>(&amp;s[i]);
	}
}</pre></div>
</details>

<details>
<summary>读者-写者问题</summary>
</details>

##### 

#### 临界区的概念？

<details open="">
<summary>展开</summary>
<p>各个进程中对临界资源（互斥资源/共享变量，一次只能给一个进程使用）进行操作的程序片段</p>
</details>

##### 

#### 同步与互斥的概念？

<details open="">
<summary>展开</summary>
<ul>
<li>同步：多个进程因为合作而使得进程的执行有一定的先后顺序。比如某个进程需要另一个进程提供的消息，获得消息之前进入阻塞态；</li>
<li>互斥：多个进程在同一时刻只有一个进程能进入临界区</li>
</ul>
</details>

##### 

#### 并发、并行、异步的区别？

<details open="">
<summary>展开</summary>
<p>并发：在一个时间段中同时有多个程序在运行，但其实任一时刻，只有一个程序在CPU上运行，宏观上的并发是通过不断的切换实现的；</p>
<p>多线程：并发运行的一段代码。是实现异步的手段</p>
<p>并行（和串行相比）：在多CPU系统中，多个程序无论宏观还是微观上都是同时执行的</p>
<p>异步（和同步相比）：同步是顺序执行，异步是在等待某个资源的时候继续做自己的事</p>
</details>

### 线程同步方式

> 为什么需要线程同步：线程有时候会和其他线程共享一些资源，比如内存、数据库等。当多个线程同时读写同一份共享资源的时候，可能会发生冲突。因此需要线程的同步，多个线程按顺序访问资源。

- **互斥量** `Mutex`：互斥量是内核对象，只有拥有互斥对象的线程才有访问互斥资源的权限。因为互斥对象只有一个，所以可以保证互斥资源不会被多个线程同时访问；当前拥有互斥对象的线程处理完任务后必须将互斥对象交出，以便其他线程访问该资源；
- **信号量** Semaphore：信号量是内核对象，它允许同一时刻多个线程访问同一资源，但是需要控制同一时刻访问此资源的最大线程数量。信号量对象保存了**最大资源计数**和**当前可用资源计数**，每增加一个线程对共享资源的访问，当前可用资源计数就减1，只要当前可用资源计数大于0，就可以发出信号量信号，如果为0，则将线程放入一个队列中等待。线程处理完共享资源后，应在离开的同时通过`ReleaseSemaphore`函数将当前可用资源数加1。如果信号量的取值只能为0或1，那么信号量就成为了互斥量；
- **事件**  Event：允许一个线程在处理完一个任务后，主动唤醒另外一个线程执行任务。事件分为手动重置事件和自动重置事件。手动重置事件被设置为激发状态后，会唤醒所有等待的线程，而且一直保持为激发状态，直到程序重新把它设置为未激发状态。自动重置事件被设置为激发状态后，会唤醒**一个**等待中的线程，然后自动恢复为未激发状态。
- **临界区** Critical Section：任意时刻只允许一个线程对临界资源进行访问。拥有临界区对象的线程可以访问该临界资源，其它试图访问该资源的线程将被挂起，直到临界区对象被释放。

#### 互斥量和临界区有什么区别？

<details open="">
<summary>展开</summary>
<p>互斥量是可以命名的，可以用于不同进程之间的同步；而临界区只能用于同一进程中线程的同步。创建互斥量需要的资源更多，因此临界区的优势是速度快，节省资源。</p>
</details>

### 进程有哪几种状态？

- 执行：进程分到CPU时间片，可以执行
- 就绪：进程已经就绪，只要分配到CPU时间片，随时可以执行
- 阻塞：有IO事件或者等待其他资源

### 进程的执行过程是什么样的，执行一个进程需要做哪些工作？

进程的执行需要经过三大步骤：编译，链接和装入。

* **编译**：将源代码编译成若干模块
* **链接**：将编译后的模块和所需要的库函数进行链接。链接包括三种形式：静态链接，装入时动态链接（将编译后的模块在链接时一边链接一边装入），运行时动态链接（在执行时才把需要的模块进行链接）
* **装入**：将模块装入内存运行

https://blog.csdn.net/qq_38623623/article/details/78306498

将进程装入内存时，通常使用分页技术，将内存分成固定大小的页，进程分为固定大小的块，加载时将进程的块装入页中，并使用页表记录。减少外部碎片。

通常操作系统还会使用虚拟内存的技术将磁盘作为内存的扩充。

### 什么是协程？

协程是一种用户态的轻量级线程，协程的调度完全由用户控制。协程拥有自己的寄存器上下文和栈。协程调度切换时，将寄存器上下文和栈保存到其他地方，在切回来的时候，恢复先前保存的寄存器上下文和栈，直接操作栈则基本没有内核切换的开销，可以不加锁的访问全局变量，所以上下文的切换非常快。

#### 协程了解吗

协程和微线程是一个东西。

协程就是子程序在执行时中断并转去执行别的子程序，在适当的时候又返回来执行。
这种子程序间的跳转不是函数调用，也不是多线程执行，所以省去了线程切换的开销，效率很高，并且不需要多线程间的锁机制，不会发生变量写冲突。

#### 那协程的底层是怎么实现的，怎么使用协程？

协程进行中断跳转时将函数的上下文存放在其他位置中，而不是存放在函数堆栈里，当处理完其他事情跳转回来的时候，取回上下文继续执行原来的函数。

#### 协程多与线程进行比较？

<details open="">
<summary>展开</summary>
<ol>
<li>
<p>一个线程可以拥有多个协程，一个进程也可以单独拥有多个协程，这样python中则能使用多核CPU。</p>
</li>
<li>
<p>线程进程都是同步机制，而协程则是异步</p>
</li>
<li>
<p>协程能保留上一次调用时的状态，每次过程重入时，就相当于进入上一次调用的状态</p>
</li>
</ol>
</details>

### 进程调度策略有哪些？

1. **批处理系统**

* **先来先服务** （FCFS first come first serve）：按照作业到达任务队列的顺序调度  FCFS是非抢占式的，易于实现，效率不高，性能不好，有利于长作业（CPU繁忙性）而不利于短作业（I/O繁忙性）。
* **短作业优先** （SHF short job first）：每次从队列里选择预计时间最短的作业运行。SJF是非抢占式的，优先照顾短作业，具有很好的性能，降低平均等待时间，提高吞吐量。但是不利于长作业，长作业可能一直处于等待状态，出现饥饿现象；完全未考虑作业的优先紧迫程度，不能用于实时系统。
* **最短剩余时间优先** 该算法首先按照作业的服务时间挑选最短的作业运行，在该作业运行期间，一旦有新作业到达系统，并且该新作业的服务时间比当前运行作业的剩余服务时间短，则发生抢占；否则，当前作业继续运行。该算法确保一旦新的短作业或短进程进入系统，能够很快得到处理。
* **高响应比优先调度算法**（Highest Reponse Ratio First, HRRF）是非抢占式的，主要用于作业调度。基本思想：每次进行作业调度时，先计算后备作业队列中每个作业的响应比，挑选最高的作业投入系统运行。响应比 = （等待时间 + 服务时间） / 服务时间 = 等待时间 / 服务时间 + 1。因为每次都需要计算响应比，所以比较耗费系统资源。

2. **交互式系统**

   交互式系统有大量的用户交互操作，在该系统中调度算法的目标是快速地进行响应。

* **时间片轮转** 用于分时系统的进程调度。基本思想：系统将CPU处理时间划分为若干个时间片（q），进程按照到达先后顺序排列。每次调度选择队首的进程，执行完1个时间片q后，计时器发出时钟中断请求，该进程移至队尾。以后每次调度都是如此。该算法能在给定的时间内响应所有用户的而请求，达到分时系统的目的。
* **优先级调度算法** 为每个进程分配一个优先级，按优先级进行调度。为了防止低优先级的进程永远等不到调度，可以随着时间的推移增加等待进程的优先级。
* **多级反馈队列**  设置多个就绪队列1、2、3...，优先级递减，时间片递增。只有等到优先级更高的队列为空时才会调度当前队列中的进程。如果进程用完了当前队列的时间片还未执行完，则会被移到下一队列。

#### 什么叫优先级反转？如何解决？

<details open="">
<summary>展开</summary>
<p>高优先级的进程等待被一个低优先级进程占用的资源时，就会出现优先级反转，即优先级较低的进程比优先级较高的进程先执行。</p>
<p>解决方法：</p>
<ul>
<li>优先级天花板(priority ceiling)：当任务申请某资源时，把该任务的优先级提升到可访问这个资源的所有任务中的最高优先级，这个优先级称为该资源的优先级天花板。简单易行。</li>
<li>优先级继承(priority inheritance)：当任务A申请共享资源S时，如果S正在被任务C使用，通过比较任务C与自身的优先级，如发现任务C的优先级小于自身的优先级，则将任务C的优先级提升到自身的优先级，任务C释放资源S后，再恢复任务C的原优先级。</li>
</ul>
</details>

### 孤儿进程和僵尸进程

* 孤儿进程是父进程退出后它的子进程还在执行，这时候这些子进程就成为孤儿进程。孤儿进程会被`init`(进程进程ID为1）收养并完成状态收集。

* 僵尸进程是指子进程完成并退出后父进程没有使用`wait()`或者`waitpid()`对它们进行状态收集，这些子进程的进程描述符仍然会留在系统中。这些子进程就成为僵尸进程。

  僵尸进程是一个已经死亡的进程，但是并没有真正被销毁。它已经放弃了几乎所有内存空间，没有任何可执行代码，也不能被调度，仅仅在进程表中保留一个位置，记载该进程的进程ID、终止状态以及资源利用信息(CPU时间，内存使用量等等)供父进程收集，除此之外，僵尸进程不再占有任何内存空间。这个僵尸进程可能会一直留在系统中直到系统重启。

  **危害**：占用进程号，而系统所能使用的进程号是有限的；占用内存。

<u>以下情况不会产生僵尸进程：</u>

- 该进程的父进程先结束了。每个进程结束的时候，系统都会扫描是否存在子进程，如果有则用Init进程接管，成为该进程的父进程，并且会调用wait等待其结束。
- 父进程调用wait或者waitpid等待子进程结束（需要每隔一段时间查询子进程是否结束）。wait系统调用会使父进程暂停执行，直到它的一个子进程结束为止。waitpid则可以加入`WNOHANG`(wait-no-hang)选项，如果没有发现结束的子进程，就会立即返回，不会将调用waitpid的进程阻塞。同时，waitpid还可以选择是等待任一子进程（同wait），还是等待指定pid的子进程，还是等待同一进程组下的任一子进程，还是等待组ID等于pid的任一子进程；
- 子进程结束时，系统会产生`SIGCHLD`(signal-child)信号，可以注册一个信号处理函数，在该函数中调用waitpid，等待所有结束的子进程（注意：一般都需要循环调用waitpid，因为在信号处理函数开始执行之前，可能已经有多个子进程结束了，而信号处理函数只执行一次，所以要循环调用将所有结束的子进程回收）；
- 也可以用`signal(SIGCLD, SIG_IGN)`(signal-ignore)通知内核，表示忽略`SIGCHLD`信号，那么子进程结束后，内核会进行回收。

### 进程的异常控制流：陷阱、中断、异常和信号

陷阱是**有意**造成的“异常”，是执行一条指令的结果。陷阱是同步的。陷阱的主要作用是实现**系统调用**。比如，进程可以执行 `syscall n` 指令向内核请求服务。当进程执行这条指令后，会中断当前的控制流，**陷入**到内核态，执行相应的系统调用。内核的处理程序在执行结束后，会将结果返回给进程，同时退回到用户态。进程此时继续执行**下一条指令**。

中断由处理器**外部**的**硬件**产生，不是执行某条指令的结果，也无法预测发生时机。由于中断独立于当前执行的程序，因此中断是异步事件。中断包括 I/O 设备发出的 I/O 中断、各种定时器引起的时钟中断、调试程序中设置的断点等引起的调试中断等。

异常是一种错误情况，是执行当前指令的结果，可能被错误处理程序修正，也可能直接终止应用程序。异常是同步的。这里特指因为执行当前指令而产生的**错误情况**，比如除法异常、缺页异常等。有些书上为了区分，也将这类“异常”称为**“故障”**。

信号是一种**更高层的**软件形式的异常，同样会中断进程的控制流，可以由进程进行处理。一个信号代表了一个消息。信号的作用是用来**通知进程**发生了某种系统事件。

更详细的可以参考：https://imageslr.github.io/2020/07/09/trap-interrupt-exception.html

### 什么是IO多路复用？怎么实现？

IO多路复用（IO Multiplexing）是指单个进程/线程就可以同时处理多个IO请求。

**实现原理：**用户将想要监视的文件描述符（File  Descriptor）添加到select/poll/epoll函数中，由内核监视，函数阻塞。一旦有文件描述符就绪（读就绪或写就绪），或者超时（设置timeout），函数就会返回，然后该进程可以进行相应的读/写操作。

#### select/poll/epoll三者的区别？

<details open="">
<summary>展开</summary>
<ul>
<li><code>select</code>：将文件描述符放入一个集合中，调用select时，将这个集合从用户空间拷贝到内核空间（缺点1：每次都要复制，<strong>开销大</strong>），由内核根据就绪状态修改该集合的内容。（缺点2）<strong>集合大小有限制</strong>，32位机默认是1024（64位：2048）；采用水平触发机制。select函数返回后，需要通过遍历这个集合，找到就绪的文件描述符（缺点3：<strong>轮询的方式效率较低</strong>），当文件描述符的数量增加时，效率会线性下降；</li>
<li><code>poll</code>：和select几乎没有区别，区别在于文件描述符的存储方式不同，poll采用链表的方式存储，没有最大存储数量的限制；</li>
<li><code>epoll</code>：通过内核和用户空间共享内存，避免了不断复制的问题；支持的同时连接数上限很高（1G左右的内存支持10W左右的连接数）；文件描述符就绪时，采用回调机制，避免了轮询（回调函数将就绪的描述符添加到一个链表中，执行epoll_wait时，返回这个链表）；支持水平触发和边缘触发，采用边缘触发机制时，只有活跃的描述符才会触发回调函数。</li>
</ul>
<p>总结，区别主要在于：</p>
<ul>
<li>一个线程/进程所能打开的最大连接数</li>
<li>文件描述符传递方式（是否复制）</li>
<li>水平触发 or 边缘触发</li>
<li>查询就绪的描述符时的效率（是否轮询）</li>
</ul>
</details>

<details open="">
<summary>什么时候使用select/poll，什么时候使用epoll？</summary>
<p>当连接数较多并且有很多的不活跃连接时，epoll的效率比其它两者高很多；但是当连接数较少并且都十分活跃的情况下，由于epoll需要很多回调，因此性能可能低于其它两者。</p>
</details>

<details open="">
<summary>什么是文件描述符？</summary>
<p>文件描述符在形式上是一个非负整数。实际上，它是一个索引值，指向内核为每一个进程所维护的该进程打开文件的记录表。当程序打开一个现有文件或者创建一个新文件时，内核向进程返回一个文件描述符。</p>
<p>内核通过文件描述符来访问文件。文件描述符指向一个文件。</p>
</details>

#### 什么是水平触发？什么是边缘触发？

<details open="">
<summary>展开</summary>
<ul>
<li>水平触发（LT，Level Trigger）模式下，只要一个文件描述符就绪，就会触发通知，如果用户程序没有一次性把数据读写完，下次还会通知；</li>
<li>边缘触发（ET，Edge Trigger）模式下，当描述符从未就绪变为就绪时通知一次，之后不会再通知，直到再次从未就绪变为就绪（缓冲区从不可读/写变为可读/写）。</li>
<li>区别：边缘触发效率更高，减少了被重复触发的次数，函数不会返回大量用户程序可能不需要的文件描述符。</li>
<li>为什么边缘触发一定要用非阻塞（non-block）IO：避免由于一个描述符的阻塞读/阻塞写操作让处理其它描述符的任务出现饥饿状态。</li>
</ul>
</details>

#### 有哪些常见的IO模型？

<details open="">
<summary>展开</summary>
<ul>
<li>同步阻塞IO（Blocking IO）：用户线程发起IO读/写操作之后，线程阻塞，直到可以开始处理数据；对CPU资源的利用率不够；</li>
<li>同步非阻塞IO（Non-blocking IO）：发起IO请求之后可以立即返回，如果没有就绪的数据，需要不断地发起IO请求直到数据就绪；不断重复请求消耗了大量的CPU资源；</li>
<li>IO多路复用</li>
<li>异步IO（Asynchronous IO）：用户线程发出IO请求之后，继续执行，由内核进行数据的读取并放在用户指定的缓冲区内，在IO完成之后通知用户线程直接使用。</li>
</ul>
</details>

### 什么是用户态和内核态？

为了限制不同程序的访问能力，防止一些程序访问其它程序的内存数据，CPU划分了用户态和内核态两个权限等级。

- 用户态只能受限地访问内存，且**不允许访问外围设备，没有占用CPU的能力**，CPU资源可以被其它程序获取；
- 内核态可以访问内存所有数据以及外围设备，也可以**进行程序的切换**。

所有用户程序都运行在用户态，但有时需要进行一些内核态的操作，比如从硬盘或者键盘读数据，这时就需要进行系统调用，使用**陷阱指令**，CPU切换到内核态，执行相应的服务，再切换为用户态并返回系统调用的结果。

#### 为什么要分用户态和内核态？

- 安全性：防止用户程序恶意或者不小心破坏系统/内存/硬件资源；
- 封装性：用户程序不需要实现更加底层的代码；
- 利于调度：如果多个用户程序都在等待键盘输入，这时就需要进行调度；统一交给操作系统调度更加方便。

#### 如何从用户态切换到内核态？

- 系统调用：比如读取命令行输入。本质上还是通过中断实现
- 用户程序发生异常时：比如缺页异常
- 外围设备的中断：外围设备完成用户请求的操作之后，会向CPU发出中断信号，这时CPU会转去处理对应的中断处理程序

#### 说一下PCB/说一下进程地址空间/

https://blog.csdn.net/qq_38499859/article/details/80057427

PCB就是进程控制块，是操作系统中的一种数据结构，用于表示进程状态，操作系统通过PCB对进程进行管理。

PCB中包含有：进程标识符，处理器状态，进程调度信息，进程控制信息

![](https://img-blog.csdn.net/20140904215636015?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvemhhbmd6aGVianV0/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)

进程地址空间内有：

* 代码段text：存放程序的二进制代码
* 初始化的数据Data：已经初始化的变量和数据
* 未初始化的数据BSS：还没有初始化的数据
* 栈
* 堆

#### 内核空间和用户空间是怎样区分的

在Linux中虚拟地址空间范围为0到4G，最高的1G地址（0xC0000000到0xFFFFFFFF）供内核使用，称为内核空间，低的3G空间（0x00000000到0xBFFFFFFF）供各个进程使用，就是用户空间。

内核空间中存放的是内核代码和数据，而进程的用户空间中存放的是用户程序的代码和数据。

## 死锁

### 什么是死锁？

在两个或者多个并发进程中，每个进程持有某种资源而又等待其它进程释放它们现在保持着的资源，在未改变这种状态之前都不能向前推进，称这一组进程产生了死锁(deadlock)。

### 死锁产生的必要条件？

- **互斥**：一个资源一次只能被一个进程使用；
- **占有并等待**：一个进程至少占有一个资源，并在等待另一个被其它进程占用的资源；
- **非抢占**：已经分配给一个进程的资源不能被强制性抢占，只能由进程完成任务之后自愿释放；
- **循环等待**：若干进程之间形成一种头尾相接的环形等待资源关系，该环路中的每个进程都在等待下一个进程所占有的资源。

产生死锁的原因主要是：
（1） 因为系统资源不足。
（2） 进程运行推进的顺序不合适。
（3） 资源分配不当等。

### 死锁的处理方法

#### 鸵鸟策略

直接忽略死锁。因为解决死锁问题的代价很高，因此鸵鸟策略这种不采取任务措施的方案会获得更高的性能。当发生死锁时不会对用户造成多大影响，或发生死锁的概率很低，可以采用鸵鸟策略。

#### 死锁预防

基本思想是破坏形成死锁的四个必要条件：

- 破坏互斥条件：允许某些资源同时被多个进程访问。但是有些资源本身并不具有这种属性，因此这种方案实用性有限；
- 破坏占有并等待条件：
  - 实行资源预先分配策略（当一个进程开始运行之前，必须一次性向系统申请它所需要的全部资源，否则不运行）；
  - 或者只允许进程在没有占用资源的时候才能申请资源（申请资源前先释放占有的资源）；
  - 缺点：很多时候无法预知一个进程所需的全部资源；同时，会降低资源利用率，降低系统的并发性；
- 破坏非抢占条件：允许进程强行抢占被其它进程占有的资源。会降低系统性能；
- 破坏循环等待条件：对所有资源统一编号，所有进程对资源的请求必须按照序号递增的顺序提出，即只有占有了编号较小的资源才能申请编号较大的资源。这样避免了占有大号资源的进程去申请小号资源。

#### 死锁避免

动态地检测资源分配状态，以确保系统处于安全状态，只有处于安全状态时才会进行资源的分配。所谓安全状态是指：即使所有进程突然请求需要的所有资源，也能存在某种对进程的资源分配顺序，使得每一个进程运行完毕。

#### 死锁解除

<details open=""><blockquote>
<p>如何检测死锁：检测有向图是否存在环；或者使用类似死锁避免的检测算法。</p>
</blockquote>
<p>死锁解除的方法：</p>
<ul>
<li>利用抢占：挂起某些进程，并抢占它的资源。但应防止某些进程被长时间挂起而处于饥饿状态；</li>
<li>利用回滚：让某些进程回退到足以解除死锁的地步，进程回退时自愿释放资源。要求系统保持进程的历史信息，设置还原点；</li>
<li>利用杀死进程：强制杀死某些进程直到死锁解除为止，可以按照优先级进行。</li>
</ul>
</details>

## 内存管理

####  操作系统的内存管理

https://www.cnblogs.com/peterYong/p/6556619.html

https://zhuanlan.zhihu.com/p/141602175

操作系统的内存管理包括物理内存管理和虚拟内存管理

* 物理内存管理包括交换与覆盖，分页管理，分段管理和段页式管理等；
* 虚拟内存管理包括虚拟内存的概念，页面置换算法，页面分配策略等；

（面试官这样问的时候，其实是希望你能讲讲虚拟内存）

### 分页和分段有什么区别？

- 页式存储：用户空间划分为大小相等的部分称为页（page），内存空间划分为同样大小的区域称为页框，分配时以页为单位，按进程需要的页数分配，逻辑上相邻的页物理上不一定相邻；
- 段式存储：用户进程地址空间按照自身逻辑关系划分为若干个段（segment）（如代码段，数据段，堆栈段），内存空间被动态划分为长度不同的区域，分配时以段为单位，每段在内存中占据连续空间，各段可以不相邻；
- 段页式存储：用户进程先按段划分，段内再按页划分，内存划分和分配按页。

区别：

- 目的不同：分页的目的是管理内存，用于虚拟内存以获得更大的地址空间；分段的目的是满足用户的需要，使程序和数据可以被划分为逻辑上独立的地址空间；
- 大小不同：段的大小不固定，由其所完成的功能决定；页的大小固定，由系统决定；
- 地址空间维度不同：分段是二维地址空间（段号+段内偏移），分页是一维地址空间（每个进程一个页表/多级页表，通过一个逻辑地址就能找到对应的物理地址）；
- 分段便于信息的保护和共享；分页的共享收到限制；
- 碎片：分段没有内碎片，但会产生外碎片；分页没有外碎片，但会产生内碎片（一个页填不满）

### 什么是虚拟内存？

> 在运行一个进程的时候，它所需要的内存空间可能大于系统的物理内存容量。通常一个进程会有4G的空间，但是物理内存并没有这么大，所以这些空间都是虚拟内存，它的地址都是逻辑地址，每次在访问的时候都需要映射成物理地址。
> 当进程访问某个逻辑地址的时候，会去查看页表，如果页表中没有相应的物理地址，说明内存中没有这页的数据，发生缺页异常，这时候进程需要把数据从磁盘拷贝到物理内存中。如果物理内存已经满了，就需要覆盖已有的页，如果这个页曾经被修改过，那么还要把它写回磁盘。

每个程序都拥有自己的地址空间，这个地址空间被分成大小相等的页，这些页被映射到物理内存；但不需要所有的页都在物理内存中，当程序引用到不在物理内存中的页时，由操作系统将缺失的部分装入物理内存。这样，对于程序来说，逻辑上似乎有很大的内存空间，只是实际上有一部分是存储在磁盘上，因此叫做虚拟内存。

虚拟内存的优点是让程序可以获得更多的可用内存。

虚拟内存的实现方式、页表/多级页表、缺页中断、不同的页面淘汰算法

##### 如何进行地址空间到物理内存的映射？

**内存管理单元**（MMU）管理着逻辑地址和物理地址的转换，其中的页表（Page  table）存储着页（逻辑地址）和页框（物理内存空间）的映射表，页表中还包含包含有效位（是在内存还是磁盘）、访问位（是否被访问过）、修改位（内存中是否被修改过）、保护位（只读还是可读写）。逻辑地址：页号+页内地址（偏移）；每个进程一个页表，放在内存，页表起始地址在PCB/寄存器中。

### 有哪些页面置换算法？

在程序运行过程中，如果要访问的页面不在内存中，就发生缺页中断从而将该页调入内存中。此时如果内存已无空闲空间，系统必须从内存中调出一个页面到磁盘中来腾出空间。页面置换算法的主要目标是使页面置换频率最低（也可以说缺页率最低）。

- **最佳页面置换算法**OPT（Optimal replacement algorithm）：置换以后不需要或者最远的将来才需要的页面，是一种理论上的算法，是最优策略；
- **先进先出**FIFO：置换在内存中驻留时间最长的页面。缺点：有可能将那些经常被访问的页面也被换出，从而使缺页率升高；
- **第二次机会算法**SCR：按FIFO选择某一页面，若其访问位为1，给第二次机会，并将访问位置0；
- **时钟算法** Clock：SCR中需要将页面在链表中移动（第二次机会的时候要将这个页面从链表头移到链表尾），时钟算法使用环形链表，再使用一个指针指向最老的页面，避免了移动页面的开销；
- **最近未使用算法**NRU（Not Recently Used）：检查访问位R、修改位M，优先置换R=M=0，其次是（R=0, M=1）；
- **最近最少使用算法**LRU（Least Recently Used）：置换出未使用时间最长的一页；实现方式：维护时间戳，或者维护一个所有页面的链表。当一个页面被访问时，将这个页面移到链表表头。这样就能保证链表表尾的页面是最近最久未访问的。
- **最不经常使用算法**NFU：置换出访问次数最少的页面



#### 局部性原理

- 时间上：最近被访问的页在不久的将来还会被访问；
- 空间上：内存中被访问的页周围的页也很可能被访问。

#### 什么是颠簸（抖动）现象

颠簸本质上是指频繁的页调度行为。进程发生缺页中断时必须置换某一页。然而，其他所有的页都在使用，它置换一个页，但又立刻再次需要这个页。因此会不断产生缺页中断，导致整个系统的效率急剧下降，这种现象称为颠簸。内存颠簸的解决策略包括：

- 修改页面置换算法；
- 降低同时运行的程序的数量；
- 终止该进程或增加物理内存容量。

### 在执行malloc申请内存的时候，操作系统是怎么做的？/内存分配的原理说一下/malloc函数底层是怎么实现的？/进程是怎么分配内存的？

https://blog.csdn.net/yusiguyuan/article/details/39496057

从操作系统层面上看，malloc是通过两个系统调用来实现的： brk和mmap

* brk是将进程数据段(.data)的最高地址指针向高处移动，这一步可以扩大进程在运行时的堆大小
* mmap是在进程的虚拟地址空间中寻找一块空闲的虚拟内存，这一步可以获得一块可以操作的堆内存。

通常，分配的内存小于128k时，使用brk调用来获得虚拟内存，大于128k时就使用mmap来获得虚拟内存。

进程先通过这两个系统调用获取或者扩大进程的虚拟内存，获得相应的虚拟地址，在访问这些虚拟地址的时候，通过缺页中断，让内核分配相应的物理内存，这样内存分配才算完成。

### 缓冲区溢出问题

<details open="">
<summary>什么是缓冲区溢出？</summary>
C 语言使用运行时栈来存储过程信息。每个函数的信息存储在一个栈帧中，包括寄存器、局部变量、参数、返回地址等。C 
对于数组引用不进行任何边界检查，因此**对越界的数组元素的写操作会破坏存储在栈中的状态信息**，这种现象称为缓冲区溢出。缓冲区溢出会破坏程序运行，也可以被用来进行攻击计算机，如使用一个指向攻击代码的指针覆盖返回地址。
</details>

<details open="">
<summary>缓冲区溢出的防范方式</summary>
<p>防范缓冲区溢出攻击的机制有三种：随机化、栈保护和限制可执行代码区域。</p>
<ul>
<li>随机化：包括栈随机化（程序开始时在栈上分配一段随机大小的空间）和地址空间布局随机化（Address-Space Layout 
Randomization，ASLR，即每次运行时程序的不同部分，包括代码段、数据段、栈、堆等都会被加载到内存空间的不同区域），但只能增加攻击一个系统的难度，不能完全保证安全。</li>
<li>栈保护：在每个函数的栈帧的局部变量和栈状态之间存储一个<strong>随机产生的</strong>特殊的值，称为金丝雀值（canary）。在恢复寄存器状态和函数返回之前，程序检测这个金丝雀值是否被改变了，如果是，那么程序异常终止。</li>
<li>限制可执行代码区域：内存页的访问形式有三种：可读、可写、可执行，只有编译器产生的那部分代码所处的内存才是可执行的，其他页限制为只允许读和写。</li>
</ul>
</details>

### 磁盘调度

过程：磁头（找到对应的盘面）；磁道（一个盘面上的同心圆环，寻道时间）；扇区（旋转时间）。为减小寻道时间的调度算法：

- 先来先服务
- 最短寻道时间优先
- 电梯算法：电梯总是保持一个方向运行，直到该方向没有请求为止，然后改变运行方向。

## 其他

### Linux理论上最多可以创建多少个进程？一个进程可以创建多少线程，和什么有关

答：32768. 因为进程的pid是用pid_t来表示的，pid_t的最大值是32768.所以理论上最多有32768个进程。

至于线程。进程最多可以创建的线程数是根据分配给调用栈的大小，以及操作系统（32位和64位不同）共同决定的。Linux32位下是300多个。

### 冯诺依曼结构有哪几个模块？分别对应现代计算机的哪几个部分？（百度安全一面）

* 存储器：内存
* 控制器：南桥北桥
* 运算器：CPU
* 输入设备：键盘
* 输出设备：显示器、网卡

###  实现一个LRU算法

用到两个数据结构：哈希+双向链表 

```
unordered_map<int,list<pair<int,int> > > cache ;// 存放键，迭代器
list<pair<int,int>> auxlist; // 存放 <键，值>
```

```
class LRUCache {
    int cap;
    list<pair<int,int>> l;// front:new back:old 存放值 新的放前面，因为前面的可以取得有效的迭代器
    map<int,list<pair<int,int> >::iterator > cache;// 存放键，迭代器
public:
    LRUCache(int capacity) {
        cap=capacity;
    }
    
    int get(int key) {
        auto mapitera = cache.find(key);
        if(mapitera==cache.end()){
            return -1;
        }else{// found
            list<pair<int,int>>::iterator listItera = mapitera->second;
            int value = (*listItera).second;

            l.erase(listItera);
            l.push_front({key,value});
            cache[key]=l.begin();

            return value;
        }
    }
    
    void put(int key, int value) {
        auto itera = cache.find(key);
        if(itera!=cache.end()){// exist
            list<pair<int,int>>::iterator listItera = itera->second;

            l.erase(listItera);
            l.push_front({key,value});
            cache[key]=l.begin();

        }else{// not exist
            if(cache.size()>=cap){
                pair<int,int> oldpair = l.back();
                l.pop_back();
                cache.erase(oldpair.first);
            }
            l.push_front({key,value});
            cache[key]=l.begin();
        }
    }
};

/**
 * Your LRUCache object will be instantiated and called as such:
 * LRUCache* obj = new LRUCache(capacity);
 * int param_1 = obj->get(key);
 * obj->put(key,value);
 */
```

#### 

### 什么是字节序？怎么判断是大端还是小端？有什么用？

https://www.cnblogs.com/broglie/p/5645200.html

字节序是对象在内存中存储的方式，大端即为最高有效位在前面，小端即为最低有效位在前面。
判断大小端的方法：使用一个union数据结构

```C++
union{
  short s;
  char c[2]; // sizeof(short)=2;
}un;
un.s=0x0102;
if(un.c[0]==1 and un.c[1]==2) cout<<"大端";
if(un.c[0]==2 and un.c[1]==1) cout<<"小端";
```

在网络编程中不同字节序的机器发送和接收的顺序不同。





## 内存管理(详细)

![image-20210417122819235](C:\Users\ninan\AppData\Roaming\Typora\typora-user-images\image-20210417122819235.png)

##### **内存管理功能**

- 内存的分配与回收：当作业或进程创建后系统会为他们分配内存空间，当结束后内存空间也会被回收。
- 地址转换：将程序中的逻辑地址转换成内存中的物理地址
- 内存空间的扩充：利用虚拟存储技术或自动覆盖技术，从逻辑上扩充内存
- 存储保护：保证个个作业在自己的内存空间内运行，互不干扰

##### 程序执行过程 **编译、链接、装入**

**编译**

- 编译：由编译程序将用户源代码编译成若干个目标模块

**链接**

- 链接：由链接程序将变以后的模块和所需要的库函数连接在一起，形成一个完整的装入模块

- 程序链接的三种方式：

- - 静态链接：在程序运行之前，就将所有模块和库函数的连在一起不再分开。
  - 装入时动态链接：将用户编译后的一组模块在装入内存的时候，边链接边装入。
  - 运行时动态链接：在运行程序执行中需要哪些模块才将其连接装入，便于修改与更新。      

**装入**

- 装入：由装入程序将装入模块装入内存运行

- 装入的三种方式：

- - 绝对装入：程序编译的时候如果已经知道要将目标模块放在内存中的哪一个位置，由于程序的逻辑地址与物理地址相同，所以直接装入
  - 可重定位装入：在多道程序环境下，多个目标模块逻辑地址的起始地址都是从0开始的，装入是对程序中的逻辑地址进行修改从而得到物理地址。比如：一个模块分配的地址在内存中是从100开始的，此时它里面标号为69的逻辑地址实际上是169。
  - 动态运行时装入：装入程序版装入模块装入内存后，并不立即把装入模块中的地址转换为绝对地址，而是推迟到程序要执行的时候才进行转换，一次装入内存后都为相对地址。

**逻辑地址和物理地址**

编译器将程序代码分成若干个模块，每个目标模块都从0号单元开始编址，这就是该目标模块的相对地址(逻辑地址)；当每个目标模块链接成一个完整的可执行目标程序的时候，连接程序会依稀按照各个模块的相对地址统一构成从0号单元开始编址的绝对地址(物理地址)

##### 内存保护

- 概念：在分配内存的时候，为了保证操作系统不受进程的影响，同时保证进程之间互不干扰，从而引出了内存保护。

- 方法：

- - 在CPU中设置一堆上下限寄存器，存放用户作业在主存中的上限地址与下限地址。当CPU要访问内存的时候，分别用这两个地址和要访问的地址做比较。
  - 重定位寄存器(基址寄存器)和界地址寄存器(限长寄存器)。重定位寄存器存储改作业的物理地址最小值；界地址寄存器存储改作业逻辑地址最大值。当CPU要访问内存的时候，分别用这两个地址数值之和与要访问的地址做比较。

##### 扩充内存

**覆盖与变换**

**覆盖**

- 概念：由于程序在运行的时候并不是任何时候都要访问程序的所有数据和代码，所以可以将用户空间分成一个固定区和若干个覆盖区。将经常使用的程序段放在固定区(不会被调出)。而那些互斥使用的程序可以交替使用覆盖区，如果不使用的话，会被调出内存。
- 特点：程序的层次结构必须由程序猿来申明，操作系统完成自动覆盖，缺点对用户不透明，增加用户负担。

![image-20210417123046567](C:\Users\ninan\AppData\Roaming\Typora\typora-user-images\image-20210417123046567.png)



**交换**

- 概念：把处于等待状态的进程从内存移到辅村，内存空间腾出来，这个叫做换出；把将要调用的进程在从辅村调到内存，这个过程叫做换入。
- 特点：交换一般是根据交换时长与执行时长比较，前者长的话就不适合；也会根据进程的优先级，首先换出优先级低的进程，但这里要防止低优先级进程饥饿；硬盘其实是分为文件区和交换区的，换出去的进程是存放在交换区。

**覆盖和交换区别**

- 覆盖是在同一个程序或者进程之间的
- 交换是在不同进程和程序之间的
- 所以覆盖技术与交换技术可以一起使用

 ##### **内存分配**

###### **4.1** **连续分配**

- 概念：连续分配为用户分配一个连续的内存空间，比如某个作业需要100mb的内存空间，就为这个作业在内存中划分一个100mb的内存空间。

- 介绍两个概念便于后面理解：

- - 内部碎片：给一个进程分配一块空间，这块空间没有用完的部分叫做内部碎片。
  - 外部碎片：给每个进程分配空间以后，内存中会存在一些区域由于太小而无法利用的空间，叫做外部碎片。      

**单一连续分配**

- 分配方法：将内存去划分为系统区域用户区，系统区为操作系统使用，剩下的用户区给**一个进程或作业**使用。
- 特点：操作简单、没有外部碎片，适合单道处理系统。但是会有大量的内部碎片浪费资源，存储效率低。

**固定分区分配**

- 分配方法：(1)分区大小相等：将内存的用户区分成大小相等的区域，每个进程只能申请一块区域；(2)分区大小不等：将内存的用户区分成大小不等的区域，分配原则是多个较小的区域、适量中等大小区域、少量的最大分区。每个进程根据大小只能申请一块区域。
- 特点：固定分区分配虽然没有外部碎片，但是会造成大量的内部碎片。分区大小相等缺乏灵活性，大的进程可能放不进去；分区大小不等可能会造成大量的内部碎片，利用率极低。

**动态分区分配**

- 分配方法：不会先划分内存区域，当进程进入内存的时候才会根据进程大小动态的为其建立分区，使分区大小刚好适合进程的需要。
- 特点：在开始是很好的，进程一次按照顺序存入内存，但是运行久了以后随着进程的消亡，会出现很多成段的内存空间，时间越来越长就会导致很多不可利用的外部碎片，降低内存的利用率。这时需要分配算法来解决

**分配算法**

- **首次适应算法**：进程进入内存之后从头开始查找第一个适合自己大小的分区。空间分区就是按照地址递增的顺序排列。算法开销小，回收后放到原位置就好。综合看这个算法性能最好。
- **最佳适应算法**：将分区从从小到大排列(容量递增)，找到最适合自己的分区，这样会有更大的分区被保留下来，满足别的进程需要。但是算法开销大，每次进程消亡产生新的区域后要重新排序。并且当使用多次后会产生很多外部碎片。
- **最坏适应算法**：将分区从从大到小排列(容量递减)，进程每次都找最大的区域来使用。可以减少难以利用的外部碎片。但是大分区很快就被用完了，大的进程可能会有饥饿的现象。算法开销也比较大。
- **邻近适应算法**：空间分区按照地址递增的顺序进行排列，是由首次适应演变而来，进程每次寻找空间，从上一次查找的地址以后开始查找(不同于首次适应，首次适应每次从开头查找)。算法开销小，大的分区也会很快被用完。
- 注意：以上进程使用空间不会产生内部碎片，当进程大小为60mb的进程找到了一块100mb的空间，他只会使用60mb，剩下的40mb会给别的进程。

###### **4.2** **非连续分配**

可以将一个进程分散的装入内存分区。根据分区的大小是否固定可以分成分页存储管理(固定)与分段存储管理(不固定)，为了避免两者的缺点，还可以二者混用成段页式存储管理。再根据进程运行作业时是否将作业的的全部代码装入内存，又分为基本分页存储管理(全部装入内存)和请求分页存储管理(非一次全装入内存)。

- **基本分页存储管理**

**思想与基本概念**

- 思想：**把主存空间划分为大小相等的块，块相对较小，作为主存的基本单元。每个进程也以块为单位划分，进程执行时，以块为单位申请内存空间**

- 概念：

- - 块：外存中的块
  - 页(页面)：进程里面的块
  - 页框(页帧)：内存中的块
  - 地址结构：地址结构包含两部分，第一部分是页号(P)，根据页号的位数可以算出地址结构可容纳最大页数；第二部分是页内偏移量(W)，可以计算出页面的大小。地址结构决定了虚拟内存的寻址空间有多大(页面的总数，比如P有二十位，那么地址空间最多有$2^{20}$个页面)。
  - 页表：为了便于在内存中找到进程的每个页面所对应的物理块，系统为每个进程建立一张页表，记录每个页面(进程中的块)在内存中的物理块号，一般放在内存中。页表项由两部分构成，第一部分存储页号，第二部分储存物理内存中的块号。
  - 注意：进程中的块的各个代码，在内存中对应的物理地址是=页表中物理内存块号+地址结构中页内偏移量

**地址变换机制及变化过程**

- 概念：主要用于将逻辑地址转换成内存中的物理地址。借助于页表来实现的。

![image-20210417123228839](C:\Users\ninan\AppData\Roaming\Typora\typora-user-images\image-20210417123228839.png)

- 步骤：

- - 1、在系统中会设置一个页表寄存器(PTR)，用来储存页表在内存中的起始地址Ｆ和页表长度M
  - 2、根据逻辑地址计算出页号和业内偏移量
  - 3、判断页号是否越界
  - 4、查询页表找到页号对应的页表项，确定页面的内存块号(第一次访存，因为页表在内存中)
  - 5、用内存块号和业内偏移量的到物理地址
  - 6、访问内存目标单元(第二次访存)

- 问题：(1)每次访问内存都需要地址转换(逻辑地址->物理地址)，浪费时间；(2)     内存中快表不能占有太大的内存，不然降低了内存利用率。

**具有快表(TLB)的地址变换机构**

- 快表(TLB)：又称为相连存储器，用来存放当前访问的若干页表象，以加速地址的变换过程。主存中的页表称为慢表。(学过组成原理的知道，页表其实和cache比较相似) 

![image-20210417123253512](C:\Users\ninan\AppData\Roaming\Typora\typora-user-images\image-20210417123253512.png)

- **步骤：**

- - 1、CPU给出逻辑地址后，由硬件进行地址转换，将页号送入高速缓存寄存器，并将次页号与快表中的页号做比较
  - 2、如果找到，直接从快表去除该页对应的页框号，与地址结构的地址偏移量计算出物理地址访存
  - 3、如果没有找到，再去慢表中找，然后如上访存，之后将这个页表项加入到快表中。注意有的系统为了节省时间，会在快表中找与在慢表中找同时进行，这样可以节约系统时间。      

**两级页表**

- 背景：一级页表，页表必须是连续存放的，因此当页面很大的时候，需要占用很多个连续的叶匡没必要让整个页表常驻内存，所以引出二级页表。

- 步骤

- - 按照地址结构将逻辑地址拆分成三部分(一级页号、二级页号、页内偏移量)
  - 从PCB中读取页目录表起始地址，再根据一级页号查页目录表，找到下一级页表在内存中的存放位置
  - 根据二级也好查表，找到最想访问的内存块号
  - 结合页内偏移量得到物理地址

 

- **基本分段式存储管理**

**背景**

分页存储是从计算机的角度设计的，目的是为了提高内存的利用率，提升计算机的性能。

分段存储的提出是考虑到程序员和用户，以满足方编程、数据共享、信息保护、动态增长、动态链接的需要。

**基本概念**

- 分段：按照进程自然划分炒年成逻辑空间，例如进程由主程序、两个子程序、栈和数据组成。于是可以把这个进程分成5段，每一段的逻辑地址从0开始编址，并分配一段连续的内存空间。(注意这里段内必须连续，段与段之间可以分散)
- 逻辑地址结构：是由两部分组成第一部分为段号S，看进程是哪一个段，段号的位数决定了进程分了多少段；第二部分为段内偏移量W，段内偏移量决定了这段进程的最大长度。
- 段表：每个进程都以一张逻辑空间与内存空间映射的段表，每个段表对应进程的一段，段表项季度该段在内存中的起始地址和长度。段表由三个部分组成：段号、段长、本段在主存中的起始地址(基址)。

**地址变换机构**

![image-20210417123312256](C:\Users\ninan\AppData\Roaming\Typora\typora-user-images\image-20210417123312256.png)

- 进切换内核程序回复进程的运行环境，从PCB中找到段表寄存器
- 根据逻辑地址得到段号、段内地址
- 将段号与段表长度比较，判断段号是否越界，产生越界中断
- 查询段表，找到对应的段表项，段表项存放的地址为段表起始地址+段号*段表项长度(因为为了节省内存空间，可以参略段表中的段号，那么计算段表项的起始地址就可以用这种方法)
- 对段内地址W进行检查，是否超过段长。如果超越就产生中断
- 根据段的基址和和段内地址得到物理地址
- 访问目标内存单元

 

- **分页与分段的区别**

1、页是信息的物理单位，分页的主要目的是为了实现离散分配，提高内存的利用率。分页仅仅是系统管理上的需求，安全是系统行为对用户是不可见的 段是信息的逻辑单位，分段的主要目的是更好地满足用户需求，一个段通常包含一组数语一个逻辑板块的信息。分段是用户可见的，用户编程时需要显示的给出段名。

2、页的大小是固定的，系统绝决定；段的大小是不固定的，取决于系统程序

3、分页的用户地址空间是一维的，程序员只需要给出一个记忆符就可以表示一个地址 分段存储管理的地址空间是二维的，程序员需要在标识一个地址的时候，既要给出段名，也要给出段内地址

4、分段比分页更容易实现信息的共享和保护 注意：不能修改的代码称为纯代码(可重入代码)，这样的代码段不是临界资源，可以共享。可修改的代码是不可以共享的（比如由很多变量的代码段） 比如：生产者进程的一个进程段，是用来判断该缓冲区此时是否可以访问，这个时候消费者进程的段表项也可以指向这里 为什么分业管理不方便实现代码共享？ 因为将生产者进程分段，由于页面的空间有限，一段可能被装入多个空间，一个空间也可能有多个代码段被装进来，所以适合共享，达不到安全的效果 

5、访问一个逻辑地址需要几次访问内存？ 单级页表：1.查内存中的页表——2.访问目标内存单元 分段：1.查询内存中的段——2.访问目标内存单元 分段与分页系统相似，分段系统也可以引入快表机构，将近期访问过的段表放到快表中，这样可以少一次访问，加快地址变换速度 

6、分页：内存空间利用率高，不会产生外部碎片，只有少量的内部碎片；不方便按照逻辑模块实现信息的共享与保护 分段：方便按照逻辑模块实现信息的共享与保护；如果段太长，为其分配很大的存储空间很不方便，容易产生外部碎片（这个虽然可以用前面的一些紧凑技术解决一部分，但是时间代价很大）

 

- **段页式管理方式**

**背景与概念**

- 背景：由于分段与分页各有利弊，页式存储提高内存利用率，段式存储反应程序逻辑结构有利于共享数据，所以可以结合二者来组成新的内存管理方式。
- 概念：首先将进程根据逻辑结构划分成若干个逻辑段，每个段都有自己的段号，然后将这些段划分成若干个大小固定的页。这样对内存空间的管理依然和分页式管理相似，将内存分成和页面大小相同的存储块，对内存分配一存储块为单位。
- 逻辑地址结构：逻辑地址结构由段号S(决定每个进程的段数)、页号P(决定每段的页数)、页内偏移量W(页面的大小和内存块的大小)组成。

**地址变换机制及变化过程**

- 根据逻辑地址得到段号、页号、页内偏移量
- 将段号S与段表长度比较，判断段号是否越界
- 查询段表，找到对应的段表项，段表项存放的地址为段表起始地址+段号*段表项长度(因为为了节省内存空间，可以参略段表中的段号，那么计算段表项的起始地址就可以用这种方法)(第一次访存)
- 将页号与页表长度比较，检查页号是否越界
- 根据页表存放块号、页号查询页表，找到对应的页表项(第二次访存)
- 根据内存块号、页内偏移量得到最终的物理地址
- 访问目标内存单元(第三次访存)
- 注意：1、段表寄存器和页表寄存器作用有两个，一是在段表或页表中寻址，二是判断是否越界；2、在一个进程中段表只能有一个，页表可以有很多个。3、分段是可见的，分页是不可见的所以段页式管理结构是二维的。4、*这里也可以引入快表机构，用段号和页号作为查询快表的关键字，如果快表命中就只需要访存一次

![image-20210417123336485](C:\Users\ninan\AppData\Roaming\Typora\typora-user-images\image-20210417123336485.png)



##### **虚拟内存**

**背景**

传统的内存管理方式具有一次性(作业必须一次性的装入内存，其实每次运行的只是一小部分)和驻留性(作业被装入内存后会一直驻留在内存中直到所有的作业结束)。这两个特性导致了内存空间存储效率极低，所以引入了虚拟内存的概念。

**局部性原理**

局部性原理分为时间局部性与空间局部性。 时间局部性：程序中的一条指令一旦执行，不久后改指令还可能再次被执行。产生时间局部性的原因是程序中存在大量的循环操作*。* 空间局部性：一旦程序访问了某个存储单元，在不久后，其附近的存储单元也会被访问。因为指令的顺序通常是顺序存储、顺序执行的。数据的存储也是向量、数组、表等形式

**概念**

基于局部性原理，在程序装入内存时，只会将程序的一部分装入内存，就可以启动程序。在程序执行过程中如果所需要的信息不在内存中，可以由操纵系统将需要的那一部分数据再调入内存。如果操作系统暂时不适用某些内容，可以将其调到外存上，从而腾出空间供别的作业使用。以上就称为虚拟存储器。

**特性**

- 多次性：是指作业在运行的过程中不是一次性全部调入内存，而是分成多次调入内存。
- 对换性：是指作业在运行过程中不需要一直存放在内存中，需要的作业从外存换入，不需要的可以暂时换出
- 虚拟性：从逻辑上扩充了内存的容量，使用户看到内存容量很大的程序却很顺利的运行在很小的内存上。

**实现**

虚拟内存的实现需要建立在离散分配的内存管理方式上 主要实现方式：

- 请求分页存储管理 

- 请求分段存储管理

- 请求段页式存储管理

- 硬件支持：

- - 一定的内存与外存空间
  - 页表机制或者段表机制
  - 中断机制，当用户要访问的程序调入内存需要中断
  - 地址变换机制，逻辑地址转换成物理地址



##### **请求分页**

请求分页管理方式时间里在分页管理方式的基础之上，请求分页系统中只需要将当前需要的一部分页面装入内存中作业就可以正常运行，当访问的页面不在内存中的时候，可以采用换入将外存中的页面换入内存。

**6.1** **请求分页的组成**

**页表机制**

为了发现和处理页面不在内存中的情况，引入来了页表机制。

- 页表机制组成： 

- - 页号：页的编号
  - 内存块号(物理块号)：储存物理地址内存中的块号      
  - 状态位P：用来表示该页是否已经调入内存      
  - 访问字段A：记录页面指标。记录本页在一段时间内被访问的次数，或者记录本页进入内存多长时间未被访问。共页面置换算法换出页面时访问。      
  - 修改位M：标记本页在调入内存后有没有被修改过，因为修改过的页面是要重新写入内存的，在选择换出时可以选择这种页面。      
  - 外存地址：用来表示该页在外存中的地址。

**缺页中断机构**

每当内存需要访问的页面不在内存中的时候，系统就会产生一个缺页中断，请求操作系统将缺少的页面调入内存。这个时候缺页的进程会发生阻塞，也为它缺少某一资源。

- 缺页中断过程：保护CPU环境、分析中断原因、装入缺页中断处理程序、回复CPU环境

- 与一般中断区别：

- - 在指令的执行期间，不是一条指令执行完成后产生中断，它是属于内中断。
  - 一条指令的执行过程中可能会发生多次中断。因为进程需要申请缺少的资源      

**地址变换机构** 

![image-20210417123438117](C:\Users\ninan\AppData\Roaming\Typora\typora-user-images\image-20210417123438117.png)



**6.2** **页面置换算法**

页面置换算法主要是决哪一页被换入，哪一页被换出。

**最佳置换算法(OPT)**

- 思想：最佳置换算法是淘汰以后不会使用的，或者是在长时间内不在访问的页面，以保证获得最低的缺页率。
- 特点：这个算法是很难实现的，由于很难预估那个页面是以后不会访问的。
- 注意：最长时间不访问和以后访问次数最小是两个概念。

**先进先出页面置换算法(FIFO)**

- 思想：淘汰最早进入内存的页面，就是在内存中驻留最久的页面。
- 特点：这个算法容易实现，但是不符合常理，因为在进程中有的页面会被经常访问到。
- 注意：这个算法可能产生换页次数不减反增的现象，称为Belady现象

**最近最久未使用置换算法(LRU)**

- 思想：选择最近最长时间没有被访问的页面
- 特点：性能好，但是需要寄存器和栈的硬件支持，

**时钟置换算法(CLOCK)**

- 简单的时钟置换算法

- - 思想：让一个指针循环扫描缓冲区，像时钟转动一样。会给每一页面增加一个附加位，称为使用位。当页面被调入内存的时候和页面被使用后将他的使用位置为1。页面需要替换的时候，指针会扫描每一页的使用位，如果为1，扫描过后置成0；如果为0，就将该页置换出去。如果所有的页面都为1的话，会继续扫描第二遍。
  - 特点：这个算法的思想其实和最近最久未使用页面置换算法相似，只是这个实现起来更加的方便。

- 高级时钟置换算法

- - 思想：再增加一位，称为修改位(因为被修改过的页面在被替换前一定要重新写回外存，所以这样可以节省时间)。      设使用位为u，修改位为m。会有以下四种情况：

![image-20210417123514490](C:\Users\ninan\AppData\Roaming\Typora\typora-user-images\image-20210417123514490.png)

- 步骤：
- 从指针开始的位置开始扫描，第一轮不对任何数据修改，查找(u=0,m=0)的页面换出
- 如果第1步失败，从头开始扫描，查找(u=0,m=1)的换出，如果不是就将每个页面的使用位置成0；
- 如果第2步失败，从头开始扫描，查找(u=0,m=0)的页面换出。如果不是就将页面的修改位改成0；
- 如果第3步失败，从头开始扫描，查找(u=0,m=0)的页面置换出。

 

**6.3** **页面分配策略**

**驻留集大小**

- 驻留集：操作系统必须决定读取多少页，决定个特定的进程分配几个页框，给每一个进程分配的物理页框的集合就是驻留集

- 注意：

- - 分配给一个进程的存储量越大，任何时候驻留在主存中的进程数就越多，可以提高处理机的时间利用率。
  - 如果一个进程在主存中的页数过少，尽管局部性原理，页面的错误率也会很高
  - 页数过多由于局部性原理，给特定的进程分配更多的主存空间对该进程的错误率没有影响。

**抖动**

刚刚换出的页面又要换入内存，刚刚换入内存的页面马上又要换出内存。主要原因是某个进程频繁访问的页面数目高于系统给他分配的物理页帧数目。

**工作集**

- 驻留集：请求分页存储管理中给进程分配的内存块的集合
- 工作集：在某段时间内，进程访问页面的集合
- 根据工作集的大小来确定驻留集的大小(驻留集>=工作集)，如果违背可能会出现抖动的现象

**三种分配策略**

- **固定分配局部置换：**每个进程分配一定的物理块，在整个运行过程中如果发生缺页，只能从这些物理块中去换出，然后再换入
- **可变分配全局置换：**为每个进程分配一定数目的物理块，操作系统也会保持出一个空闲的物理块队列。当发生缺页的时候，系统会将空闲的物理块取出给这个进程使用。这个方法是最灵活的，也是最容易实现的。
- **可变分配局部置换：**操作系统为每一个进程分配一定数目的物理块，当进程缺页的时候只能从该进程的内部的页面选出一页换出，不会影响其他进程。如果经常出现缺页，系统会为该进程再分配一些物理块供他使用，这里体现了动态性。

**调入页面的时机**

为了确定系统进程的运行时所需要的页面调入内存的时机，会有两个策略预调页策略和请求调页策略，一般的系统中会结合使用。 *预调页策略：*根据局部性原理，一次调入多个页面肯定比一次调入一个页面更高效，但是一次调入太多的页面会浪费内存使用率。所以先预计哪些页面会使用，就先将其调入。这个方法主要用于进程的首次调入，由程序员和用户完成。 请求调页策略：在运行过程中，如果进程需要哪个页面不在内存中，就会提出请求，系统将页面调入内存。这个方式一次只能调入一页，调入调出会加大I/O开销。

**从何处调入页面**

请求分页系统的外存其实是分成两个区的，一个文件区(用来存放文件)和对换区(用来存放对换的页面)。对换区通产采用连续分配，文件区采用离散分配，所以对换区的效率更高。 如果系统拥有足够的对换区空间，可以全部从对换区调入内存，以提高调页的速度。这样的话需要在进程运行前将文件区的作业复制到对换区。 如果缺少足够的对换区空间，凡是不会被修改的文件放到文件区，会被修改的页面放到对换区。因为**那些不被修改的页面不需要换出**。 * UNIX方式：与进程有关的页面放在文件区，对换出来的页面放在对换区。

#### **文件读写使用的系统调用**

![image-20210417123604093](C:\Users\ninan\AppData\Roaming\Typora\typora-user-images\image-20210417123604093.png)

#### 异常和中断的差别

![image-20210417123635154](C:\Users\ninan\AppData\Roaming\Typora\typora-user-images\image-20210417123635154.png)